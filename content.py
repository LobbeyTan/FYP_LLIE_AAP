title = "Toward Simultaneous Grayscale Low-Light Enhancement and Color Restoration"

abstract = "The study of low-light image enhancements (LLIE) is to translate images from low light distribution to normal light distribution which could recover the important details in the image and improve the visibility of the objects in the image. Thus far, there are different kinds of algorithms being proposed to tackle this problem and extensive research has been done to improve the enhancement results which can be generally categorized as histogram equalization, dehazing, Retinex method, and deep learning method. The deep learning method has proved to be able to achieve better enhancement results and a few state-of-the-art algorithms are based on deep neural networks. In this work, we proposed an unsupervised Generative Adversarial Network (GAN) that can be trained without paired low-to-normal light datasets. Here we introduce a custom attention module that can identify the degree of enhancement of the regional images. Currently, we used a few qualitative evaluation methods like Structural Similarity (SSIM) and Peak-Signal-To-Noise Ratio (PSNR) to evaluate the effectiveness of our proposed solution. Moreover, we plan to further extend this work by applying LLIE in high-level vision tasks such as night-time pedestrian detection and low-light object detection to show that our solution can be jointly trained with different computer vision algorithms and achieve better accuracy in low light conditions."

keywords = "Keywords: Low-light image enhancements, Low-light object detection, Generative Adversarial Network (GAN), unsupervised learning, unpair image-to-image translation, attention mechanism."

network_architecture = "Our GAN model is built on top of EnlightenGAN (Jiang, et al., 2019)[4] which consist of one generator and two discriminators to direct global and local information. The generator is implemented with Unet with Residual Block architecture and is guided by our proposed custom attention module. As shown in figure below, the proposed generator architecture diagram, the generator consists of convolutional blocks, attentional blocks, upsampling layers and downsampling layers."

enhanced_result_desc = "We compared our model results on low-light enhancement with six different state-of-the-art methods, including Illumination Map Estimation based approach (LIME)[3], Weighted Variational Model for Simultaneous Reflectance and Illumination Estimation (SRIE)[1], Deep Retinex Decomposition method (RetinexNet)[6], Kindling the Darkness with Retinex theory (KinD)[7], unsupervised GAN training without Paired Supervision (EnlightenGAN)[4] and Zero-Reference Deep Curve Estimation (ZeroDCE)[2]."

detection_result_desc = "After getting the enhanced low-light images from all the models, we then use the pretrained YoloV7 for object detection on those enhanced results. The object detection is running on Exclusive Dark (ExDark)[5] dataset which the ground truth labels are present. We use the mean average precison (mAP) and mean average recall (mAR) to validate the models performance."

powerpoint_embed_link = "https://56bfgb-my.sharepoint.com/personal/lobbeytan_56bfgb_onmicrosoft_com/_layouts/15/Doc.aspx?sourcedoc={df2a4a60-5fbe-4333-8f57-4dbdd930ab7c}&amp;action=embedview&amp;wdAr=1.7777777777777777&amp;wdEaaCheck=1"